---
layout: page
title: Methods
---

<h1 id="logistics">Methods<br>
</h1>
We plan to divide the project into three stages: Exploratory Data Analysis (EDA), Supervised Learning, and Unsupervised Learning.

<h2 id="logistics">Dataset<br>
</h2>
For this project, we will be using two datasets:
<br>
Covid Vaccine Tweets up until February 28, 2020
<br>
Stanford Sentiment Treeback

<h2 id="logistics">Exploratory Data Analysis (EDA)<br>
</h2>
In the EDA, we plan to explore the geographical distributions of the tweets as well as other information such as the number of friends and followers of the users. We expect this information to provide us with some insights about the user such as his or her location and scale of social network on the internet.

<h2 id="logistics">Supervised Learning<br>
</h2>
For supervised learning, we plan to divide it into two parts: (1) dictionary-based sentiment analysis on the tweets using SentiWords and VADER (Valence Aware Dictionary for Sentiment Reasoning); (2) training a model using the Stanford Sentiment Treebank (SST) and testing on the Covid Vaccine Tweets (CVT) dataset. 

<h3 id="logistics">Dictionary-based Sentiment Analysis<br>
</h3>
For this approach, we plan to calculate the sentiment scores based on different sentiment dictionaries and aggregate the word-level sentiment scores to obtain a document-level sentiment level on each tweet. We will compare the results of using different sentiment dictionaries as well as the model trained using the SST dataset as described below.

<h3 id="logistics">Neural Network-based Sentiment Analysis<br>
</h3>
For this part of the project, we will use the SST as our training data and the CVT as our testing data. This can also be divided into two parts. The first part will be fine-tuning pre-trained LSTM-based and Transformer-based models such as BERT using the SST dataset. The second part is to build an LSTM model as a baseline to compare the performances of these two models as well as the vanilla dictionary-based models described above.
<br>
To evaluate the result, we can compare the prediction of our model with the Dictionary-based results. In addition, we can also use Dictionary-based results as the labels of CVT and use the F1 score and confusion matrix to evaluate our model.

<h2 id="logistics">Unsupervised Learning<br>
</h2>

<h3 id="logistics">Topic Modeling<br>
</h3>
Aside from building a supervised classification model, we will check the nature of the data using unsupervised learning, performing clustering experiments on different clustering algorithms taught in class, such as k-means clustering, GMM, hierarchical clustering, DBSCAN, etc., to uncover the inherent topic upon which the approval or skepticism of COVID vaccine is built. This task mainly evolves around the tweets.
<br>
Common evaluation metrics such as silhouette score will be used. We will also use PCA (the first two principal components) and tSNE to visualize our high dimensional clustering result.

